{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goal: plot training curves for e2e. There was probably an earlier way to do this, but I forget\n",
    "Doing this from scratch, 25 sept 2021\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from ulfs import graphing, graphing_common\n",
    "importlib.reload(graphing)\n",
    "importlib.reload(graphing_common)\n",
    "\n",
    "log_dir = '../../logs'\n",
    "\n",
    "ref = 'ibe124'\n",
    "send_arch = 'RNNAutoReg:LSTM'\n",
    "recv_arch = 'RNN:LSTM'\n",
    "\n",
    "def plot_scenario(ref, send_arch, recv_arch):\n",
    "    send_arch_filename = send_arch.replace(':', '')\n",
    "    recv_arch_filename = recv_arch.replace(':', '')\n",
    "    files = glob.glob(f'{log_dir}/log_*_{ref}_{send_arch_filename}_{recv_arch_filename}*.log')\n",
    "    assert len(files) > 0\n",
    "    files = [file for file in files if 'recv' not in file and 'send' not in file]\n",
    "    assert len(files) > 0\n",
    "    file_by_grammar = {}\n",
    "    grammars = []\n",
    "    for file in files:\n",
    "        grammar = file.split(f'{send_arch_filename}_{recv_arch_filename}_')[1].split('_')[0]\n",
    "#         print('    ', grammar, file)\n",
    "        file_by_grammar[grammar] = file\n",
    "        grammars.append(grammar)\n",
    "    assert len(grammars) > 0\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, value_key in enumerate(['e2e_loss', 'e2e_acc', 'send_acc', 'recv_acc']):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        for grammar in sorted(grammars):\n",
    "    #         print(grammar)\n",
    "            filepath = file_by_grammar[grammar]\n",
    "            y_lims = None\n",
    "            if value_key.endswith('_acc'):\n",
    "                y_lims = [0, 1]\n",
    "            graphing.plot_logfile2(\n",
    "                logfile=filepath, step_key='episode', value_key=value_key, title=value_key, y_lims=y_lims,\n",
    "                label=grammar, units='thousands', skip_record_types=['sup_train_res'],\n",
    "            )\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "for send_arch in ['FC2L', 'RNNAutoReg:LSTM', 'TransDecSoft']:\n",
    "    print(send_arch, recv_arch)\n",
    "    plot_scenario(ref=ref, send_arch=send_arch, recv_arch=recv_arch)\n",
    "\n",
    "# {\"sps\": 13, \"elapsed_time\": 1685.0098643302917, \"e2e_loss\": -0.7471874964237213,\n",
    "# \"e2e_acc\": 0.7478437483310699, \"r_mean\": 0.7471874964237213, \"r_std\": 0.4346870410442352,\n",
    "# \"rho\": 0.34620082867986396, \"recv_acc\": 0.3296875059604645,\n",
    "# \"send_acc\": 0.3695312440395355, \"episode\": 21971}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a28040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "in this section, we'll try to plot ci95 over multiple runs\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from ulfs import graphing, graphing_common\n",
    "importlib.reload(graphing)\n",
    "importlib.reload(graphing_common)\n",
    "\n",
    "# log_dir = '../../pull'\n",
    "log_dir = '../../logs'\n",
    "\n",
    "# refs = ['ibe122']\n",
    "# refs = ['ibe122', 'ibe123', 'ibe124', 'ibe125', 'ibe126']\n",
    "refs = [f'ibe{i}' for i in range(122, 132)]\n",
    "# refs = [refs[2]]\n",
    "send_arch = 'RNNAutoReg:LSTM'\n",
    "recv_arch = 'RNN:LSTM'\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "def aggregate_series(files, value_key, grammar, num_bins):\n",
    "    step_min, step_max = None, None\n",
    "    data_by_file = {}\n",
    "    for file in files:\n",
    "        steps, values, value_by_epoch, time_by_epoch = graphing.get_log_results(\n",
    "            logfile=file, step_key='episode', skip_record_types=['sup_train_res'], value_key=value_key,\n",
    "            units='thousands',\n",
    "        )\n",
    "        data_by_file[file] = {'steps': steps, 'values': values, 'value_by_epoch': value_by_epoch, 'time_by_epoch': time_by_epoch}\n",
    "        _min, _max = min(steps), max(steps)\n",
    "        if step_min is None or _min < step_min:\n",
    "            step_min = _min\n",
    "        if step_max is None or _max < step_max:\n",
    "            step_max = _max\n",
    "    min_count = min([len(data_by_file[file]['steps']) for file in files])\n",
    "    print('min_count', min_count)\n",
    "#     bins = np.linspace(step_min + (step_max - step_min) / num_bins, step_max, min_count // 100)\n",
    "#     num_bins = 50\n",
    "    bins = np.linspace(step_min + (step_max - step_min) / num_bins, step_max, num_bins)\n",
    "\n",
    "    steps_all = []\n",
    "    values_all = []\n",
    "    refs_all = []\n",
    "    value_keys_all = []\n",
    "    grammar_all = []\n",
    "    df_dict = {}\n",
    "    for i, file in enumerate(files):\n",
    "        steps, values, value_by_epoch, time_by_epoch = map(data_by_file[file].__getitem__, [\n",
    "            'steps', 'values', 'value_by_epoch', 'time_by_epoch'])\n",
    "        means, edges, bin_numbers = stats.binned_statistic(steps, values, bins=bins)\n",
    "        data_by_file[file]['means'] = means\n",
    "        steps_all += list(edges)[1:]\n",
    "        values_all += list(means)\n",
    "        refs_all += len(means) * [i]\n",
    "        value_keys_all += len(means) * [value_key]\n",
    "        grammar_all += len(means) * [grammar]\n",
    "        df_dict[i] = means\n",
    "    df = pd.DataFrame({\n",
    "        'step': steps_all, 'value': values_all, 'ref': refs_all, 'value_key': value_keys_all,\n",
    "        'grammar': grammar_all})\n",
    "    return df\n",
    "\n",
    "def aggregate_data(refs, send_arch, recv_arch, num_bins):\n",
    "    print(send_arch, recv_arch)\n",
    "    send_arch_filename = send_arch.replace(':', '')\n",
    "    recv_arch_filename = recv_arch.replace(':', '')\n",
    "    files_by_grammar = defaultdict(list)\n",
    "    grammars_set = set()\n",
    "    for ref in refs:\n",
    "        files = glob.glob(f'{log_dir}/log_*_{ref}_{send_arch_filename}_{recv_arch_filename}*.log')\n",
    "        assert len(files) > 0\n",
    "        files = [file for file in files if 'recv' not in file and 'send' not in file]\n",
    "        assert len(files) > 0\n",
    "        grammars = []\n",
    "        for file in files:\n",
    "            grammar = file.split(f'{send_arch_filename}_{recv_arch_filename}_')[1].split('_')[0]\n",
    "            files_by_grammar[grammar].append(file)\n",
    "            grammars_set.add(grammar)\n",
    "    assert len(grammars_set) > 0\n",
    "    grammars = sorted(list(grammars_set))\n",
    "\n",
    "    df_by_value_key = {}\n",
    "\n",
    "    df_all = []\n",
    "    for i, value_key in enumerate(['e2e_loss', 'e2e_acc', 'send_acc', 'recv_acc']):\n",
    "        print(i, value_key)\n",
    "        df_l = []\n",
    "        grammar_display = {\n",
    "            'Comp': 'comp',\n",
    "            'Cumrot': 'rot',\n",
    "            'Permute': 'perm',\n",
    "            'RandomProj': 'proj',\n",
    "            'ShuffleWordsDet': 'shufdet'\n",
    "        }\n",
    "        for grammar in grammars:\n",
    "            files = files_by_grammar[grammar]\n",
    "            df = aggregate_series(files=files, value_key=value_key, grammar=grammar_display[grammar], num_bins=num_bins)\n",
    "            df_l.append(df)\n",
    "        df = pd.concat(df_l, ignore_index=True)\n",
    "        df_all.append(df)\n",
    "        df_by_value_key[value_key] = df\n",
    "    df_all = pd.concat(df_all, ignore_index=True)\n",
    "    df_all.to_csv(f'{send_arch_filename}_{recv_arch_filename}.csv')\n",
    "    return df_by_value_key\n",
    "\n",
    "# for send_arch in ['FC2L', 'RNNAutoReg:LSTM', 'TransDecSoft']:\n",
    "df_by_value_key_by_send_arch = {}\n",
    "for send_arch in ['RNNAutoReg:LSTM']:\n",
    "    print(send_arch, recv_arch)\n",
    "    df_by_value_key = aggregate_data(refs=refs, send_arch=send_arch, recv_arch=recv_arch, num_bins=50)\n",
    "    df_by_value_key_by_send_arch[send_arch] = df_by_value_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a52704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scenario(df_by_value_key):\n",
    "    send_arch_filename = send_arch.replace(':', '')\n",
    "    recv_arch_filename = recv_arch.replace(':', '')\n",
    "\n",
    "    df_all = []\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, value_key in enumerate(['e2e_loss', 'e2e_acc', 'send_acc', 'recv_acc']):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        df = df_by_value_key[value_key]\n",
    "        sns.lineplot(data=df, x='step', y='value', hue='grammar')\n",
    "        if value_key.endswith('_acc'):\n",
    "            plt.ylim([0, 1])\n",
    "        plt.xlabel('steps (thousands)')\n",
    "        value_key_tex = {\n",
    "            'e2e_acc': r'$\\mathrm{acc}_{e2e}$',\n",
    "            'send_acc': r'$\\mathrm{acc}_{send}$',\n",
    "            'recv_acc': r'$\\mathrm{acc}_{recv}$',\n",
    "            'e2e_loss': r'$\\mathrm{loss}_{e2e}$',\n",
    "        }.get(value_key, value_key)\n",
    "        plt.ylabel(value_key_tex)\n",
    "        plt.title(value_key_tex)\n",
    "    plt.savefig(f'{send_arch_filename}_{recv_arch_filename}.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# SMALL_SIZE = 16\n",
    "# MEDIUM_SIZE = 20\n",
    "# BIGGER_SIZE = 24\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "sns.set_style(style='white')\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# for send_arch in ['FC2L', 'RNNAutoReg:LSTM', 'TransDecSoft']:\n",
    "for send_arch in ['RNNAutoReg:LSTM']:\n",
    "    print(send_arch, recv_arch)\n",
    "    plot_scenario(df_by_value_key_by_send_arch[send_arch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def dump_tall_csv(send_arch, df_by_value_key):\n",
    "    fieldnames = ['value_key', 'grammar', 'value', 'step']\n",
    "    df_by_ref = {}\n",
    "\n",
    "    df_all = pd.concat(df_by_value_key.values())\n",
    "    print('df_all', df_all)\n",
    "    for ref in range(10):\n",
    "        _df = df_all[df_all.ref==ref]\n",
    "        print('_df', _df)\n",
    "\n",
    "#     for ref in range(10):\n",
    "#         _df = df_by_value_key\n",
    "#         for value_key, df in df_by_value_key.items():\n",
    "            \n",
    "#     with open(f'{send_arch}_tall.csv', 'w') as f:\n",
    "#         dict_writer = csv.DictWriter(f, fieldnames)\n",
    "#         dict_writer.writeheader()\n",
    "#         for value_key, df in df_by_value_key.items():\n",
    "#             for row in df.to_dict(orient=\"records\"):\n",
    "#                 print(row)\n",
    "#                 asdsdf\n",
    "\n",
    "for send_arch in ['RNNAutoReg:LSTM']:\n",
    "    print(send_arch, recv_arch)\n",
    "    dump_tall_csv(send_arch, df_by_value_key_by_send_arch[send_arch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a034b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='monospace')\n",
    "\n",
    "X = np.arange(5)\n",
    "Y = X * X\n",
    "plt.plot(X, Y)\n",
    "# plt.xlabel(r'$\\mathrm{foo} x^2$')\n",
    "plt.xlabel('HelloWorld', variant='small-caps', family='sans-serif')\n",
    "# plt.title(f'$x^2$ HelloWorld', variant='small-caps')\n",
    "# plt.title('HelloWorld', variant='small-caps')\n",
    "# plt.title('HelloWorld', stretch='ultra-expanded')\n",
    "plt.show()\n",
    "\n",
    "# ax.text(0.3, 0.7, \"Hello!\", fontdict = {'stretch': 'ultra-expanded'})\n",
    "# ax.text(0.7, 0.3, \"Hello!\", fontdict = {'stretch': 'condensed'})\n",
    "# ax.text(0.7, 0.7, \"Hello!\", fontdict = {'variant': 'small-caps'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20326d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from os.path import join\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except:\n",
    "    print('installing seaborn')\n",
    "    os.system('pip install seaborn')\n",
    "    import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "def set_size(width, fraction=1):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Document textwidth or columnwidth in pts\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio\n",
    "\n",
    "    fig_dim = (fig_width_in, fig_height_in)\n",
    "\n",
    "    return fig_dim\n",
    "\n",
    "width = 395\n",
    "fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
    "\n",
    "if os.system('pdflatex --version') != 0:\n",
    "    print('installing texlife')\n",
    "    os.system('apt-get update')\n",
    "    os.system('apt-get install -y texlive-full')\n",
    "assert os.system('pdflatex --version') == 0\n",
    "\n",
    "style_sheet_dir = path.join(mpl.__path__[0], 'mpl-data', 'stylelib')\n",
    "# print(\"Your style sheets are located at: {}\".format(style_sheet_dir))\n",
    "with open(join(style_sheet_dir, 'tex.mplstyle'), 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "text.usetex: True\n",
    "font.family: serif\n",
    "axes.labelsize: 10\n",
    "font.size: 10     \n",
    "legend.fontsize: 8\n",
    "xtick.labelsize: 8\n",
    "ytick.labelsize: 8\n",
    "\"\"\")\n",
    "\n",
    "# Using seaborn's style\n",
    "plt.style.use('seaborn')\n",
    "# With LaTex fonts\n",
    "plt.style.use('tex')\n",
    "\n",
    "x = np.linspace(0, 2 * np.pi, 100)\n",
    "# Initialise figure instance\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=set_size(width))\n",
    "\n",
    "# Plot\n",
    "# ax.plot(x, np.sin(x))\n",
    "# ax.set_xlim(0, 2 * np.pi)\n",
    "# ax.set_xlabel(r'$\\theta$')\n",
    "# ax.set_ylabel(r'$\\sin (\\theta)$')\n",
    "\n",
    "df = pd.DataFrame({'x': [0,0,1,1,2,2], 'y': [1,0,2,1,3,2]})\n",
    "sns.lineplot(ax=ax1, data=df, x='x', y='y')\n",
    "\n",
    "df = pd.DataFrame({'x': [0,0,1,1,2,2], 'y': [1,3,2,5,3,11]})\n",
    "sns.lineplot(ax=ax2, data=df, x='x', y='y')\n",
    "\n",
    "df = pd.DataFrame({'x': [0,0,1,1,2,2], 'y': [1,3,2,5,3,11]})\n",
    "sns.lineplot(ax=ax3, data=df, x='x', y='y')\n",
    "\n",
    "df = pd.DataFrame({'x': [0,0,1,1,2,2], 'y': [1,3,2,5,3,11]})\n",
    "sns.lineplot(ax=ax4, data=df, x='x', y='y')\n",
    "ax4.set_xlabel('foo $2^3$')\n",
    "\n",
    "# Save and remove excess whitespace\n",
    "fig.savefig('example_1.pdf', format='pdf', bbox_inches='tight')\n",
    "os.system('cp example_1.pdf ../../pull/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
